{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load analyze_sparseval\n",
    "#!/usr/bin/env python3\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import glob\n",
    "import numpy as np\n",
    "import json\n",
    "import jiwer\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import random\n",
    "import pickle\n",
    "import json\n",
    "\n",
    "from nltk.tree import Tree\n",
    "from pstree import *\n",
    "\n",
    "random.seed(0)\n",
    "\n",
    "columns = ['sent_num', \n",
    "'bracket_match', 'bracket_gold', 'bracket_test', 'bracket_cross', \n",
    "'overall_match', 'overall_gold', 'overall_test', \n",
    "'open_match', 'open_gold', 'open_test']\n",
    "\n",
    "def comp_fsent(row, score_type):\n",
    "    col_match = score_type + '_match' \n",
    "    col_gold = score_type + '_gold'\n",
    "    col_test = score_type + '_test'\n",
    "    if row[col_test] + row[col_gold] == 0:\n",
    "        return 0.0\n",
    "    fscore = 2 * row[col_match] / (row[col_test] + row[col_gold])\n",
    "    return fscore\n",
    "\n",
    "def calc_prf(match, gold, test):\n",
    "    precision = match / float(test)\n",
    "    recall = match / float(gold)\n",
    "    fscore = 2 * match / (float(test + gold))\n",
    "    return precision, recall, fscore\n",
    "\n",
    "def read_result_file(asr_dir, split, model, dep_type):\n",
    "    filename = os.path.join(asr_dir, \"{}_{}_dep_{}.log\".format(split, dep_type, model))\n",
    "    ll = open(filename).readlines()\n",
    "    lines = ll[4:-13]\n",
    "    lines = [x.split() for x in lines]\n",
    "    df = pd.DataFrame(lines, columns=columns, dtype=float)\n",
    "    pred_file = os.path.join(asr_dir, \"{}_asr_{}.parse\".format(split, model))\n",
    "    parses = open(pred_file).readlines()\n",
    "    parses = [x.strip() for x in parses]\n",
    "    df['pred_parse'] = parses\n",
    "    pscore_file = os.path.join(asr_dir, \"{}_asr_{}.scores\".format(split, model))\n",
    "    pscores = open(pscore_file).readlines()\n",
    "    pscores = [float(x.strip().split()[0]) for x in pscores]\n",
    "    df['pscores_raw'] = pscores \n",
    "    return df\n",
    "\n",
    "def add_parses(asr_dir, split, model, df):\n",
    "    pred_file = os.path.join(asr_dir, \"{}_asr_{}.parse\".format(split, model))\n",
    "    parses = open(pred_file).readlines()\n",
    "    parses = [x.strip() for x in parses]\n",
    "    df['pred_parse'] = parses\n",
    "    pscore_file = os.path.join(asr_dir, \"{}_asr_{}.scores\".format(split, model))\n",
    "    pscores = open(pscore_file).readlines()\n",
    "    pscores = [float(x.strip().split()[0]) for x in pscores]\n",
    "    df['pscores_raw'] = pscores \n",
    "    return df\n",
    "\n",
    "def add_f1_scores(df):\n",
    "    df['overall_f1'] = df.apply(lambda x: comp_fsent(x, 'overall'), axis=1)\n",
    "    df['open_f1'] = df.apply(lambda x: comp_fsent(x, 'open'), axis=1)\n",
    "    df['bracket_f1'] = df.apply(lambda x: comp_fsent(x, 'bracket'), axis=1)\n",
    "    return df\n",
    "\n",
    "def get_merge_df(asr_dir, split, model, dep_type, df):\n",
    "    sent_id_file = os.path.join(asr_dir, \"{}_asr_sent_ids.txt\".format(split))\n",
    "    tsv_file = \"asr_output/nbest/\" + split + \"_asr_pa_nbest.tsv\"\n",
    "    tsv_df = pd.read_csv(tsv_file, sep=\"\\t\")\n",
    "    tsv_df = tsv_df.rename(columns={'mrg':'gold_parse'})\n",
    "    sent_ids = open(sent_id_file).readlines()\n",
    "    sent_ids = [x.strip() for x in sent_ids]\n",
    "    #df = read_result_file(asr_dir, split, model, dep_type)\n",
    "    df['sent_id'] = sent_ids\n",
    "    df['asr_hyp'] = df.sent_id.apply(lambda x: int(x.split('-')[1]))\n",
    "    merge_df = pd.merge(df, tsv_df, on='sent_id')\n",
    "    merge_df['asr_score'] = -(merge_df['lm_cost'] + 0.1*merge_df['ac_cost'])\n",
    "    asr_min = merge_df.asr_score.min()\n",
    "    merge_df['asr_len'] = merge_df['asr_sent'].apply(lambda x: len(x.split()))\n",
    "    merge_df['asr_norm'] = (merge_df['asr_score'] - asr_min) / merge_df['asr_len']\n",
    "    merge_df['wer'] = merge_df.apply(lambda row: jiwer.wer(row.orig_sent, row.asr_sent), axis=1)\n",
    "    \n",
    "    pscore_min = merge_df['pscores_raw'].min()\n",
    "    merge_df['parse_score'] = (merge_df['pscores_raw'] - pscore_min) / merge_df['asr_len']\n",
    "    merge_df['edit_count'] = merge_df['pred_parse'].apply(lambda x: x.count('EDITED'))\n",
    "    merge_df['intj_count'] = merge_df['pred_parse'].apply(lambda x: x.count('INTJ'))\n",
    "    merge_df['np_count'] = merge_df['pred_parse'].apply(lambda x: x.count('NP'))\n",
    "    merge_df['vp_count'] = merge_df['pred_parse'].apply(lambda x: x.count('VP'))\n",
    "    merge_df['pp_count'] = merge_df['pred_parse'].apply(lambda x: x.count('PP'))\n",
    "    merge_df['depth_proxy'] = merge_df['pred_parse'].apply(lambda x: x.count('('))\n",
    "    merge_df['depth'] = merge_df['pred_parse'].apply(lambda x: Tree.fromstring(x).height())\n",
    "\n",
    "    # analysis by sentence:\n",
    "    #merge_df.groupby('orig_id').agg(\n",
    "    #        best_asr=pd.NamedAgg(column='asr_score', aggfunc='max'))\n",
    "    return merge_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pairs(df, feat_list, n=5):\n",
    "    pair_idx = {}\n",
    "    X, Y, WER_diffs = [], [], []\n",
    "    for orig_id, sent_df in df.groupby('orig_id'):\n",
    "        pair_idx[orig_id] = []\n",
    "        if len(sent_df) < 2:\n",
    "            #print(orig_id)\n",
    "            continue\n",
    "        min_loc = sent_df.overall_f1.idxmin()\n",
    "        max_loc = sent_df.overall_f1.idxmax()\n",
    "        # always include the biggest difference:\n",
    "        y = 1\n",
    "        wer_delta = sent_df.loc[max_loc].wer - sent_df.loc[min_loc].wer\n",
    "        x = []\n",
    "        pair_idx[orig_id].append((max_loc, min_loc))\n",
    "        for feat in feat_list:\n",
    "            featval = sent_df.loc[max_loc][feat] - sent_df.loc[min_loc][feat]\n",
    "            x.append(featval)\n",
    "        Y.append(y)\n",
    "        X.append(x)\n",
    "        WER_diffs.append(wer_delta)\n",
    "        \n",
    "        # sample and compare with min, max\n",
    "        for _ in range(n):\n",
    "            sample_row = sent_df.sample(1)\n",
    "            idx = sample_row.index.values[0]\n",
    "            pair_idx[orig_id].append((max_loc, idx))\n",
    "            sample_f1 = sample_row.overall_f1.values[0] \n",
    "            \n",
    "            diff = sent_df.loc[max_loc].overall_f1 - sample_f1\n",
    "            wer_delta = sent_df.loc[max_loc].wer - sample_row.wer.values[0]\n",
    "            x = []\n",
    "            for feat in feat_list:\n",
    "                featval = sent_df.loc[max_loc][feat] - sample_row[feat].values[0]\n",
    "                x.append(featval)\n",
    "            if diff > 0:\n",
    "                y = 1\n",
    "            else:\n",
    "                y = 0\n",
    "            Y.append(y)\n",
    "            X.append(x)\n",
    "            WER_diffs.append(wer_delta)\n",
    "            \n",
    "            diff = sent_df.loc[min_loc].overall_f1 - sample_f1\n",
    "            wer_delta = sent_df.loc[min_loc].wer - sample_row.wer.values[0]\n",
    "            pair_idx[orig_id].append((min_loc, idx))\n",
    "            x = []\n",
    "            for feat in feat_list:\n",
    "                featval = sent_df.loc[min_loc][feat] - sample_row[feat].values[0]\n",
    "                x.append(featval)\n",
    "            \n",
    "            if diff > 0:\n",
    "                y = 1\n",
    "            else:\n",
    "                y = 0\n",
    "            Y.append(y)\n",
    "            X.append(x)\n",
    "            WER_diffs.append(wer_delta)\n",
    "        \n",
    "        # sample random pair\n",
    "        for _ in range(n):\n",
    "            pair_df = sent_df.sample(2)\n",
    "            idx = pair_df.index.values\n",
    "            pair_idx[orig_id].append((idx[0], idx[1]))\n",
    "            diff = pair_df.overall_f1.values[0] - pair_df.overall_f1.values[1]\n",
    "            wer_delta = pair_df.wer.values[0] - pair_df.wer.values[1]\n",
    "            x = []\n",
    "            for feat in feat_list:\n",
    "                featval = pair_df[feat].values[0] -  pair_df[feat].values[1]\n",
    "                x.append(featval)\n",
    "            if diff > 0:\n",
    "                y = 1\n",
    "            else:\n",
    "                y = 0\n",
    "            Y.append(y)\n",
    "            X.append(x)\n",
    "            WER_diffs.append(wer_delta)\n",
    "    return np.array(X), Y, WER_diffs, pair_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/homes/ttmt001/transitory/self-attentive-parser/results/bert'\n",
    "gold_dir = '/homes/ttmt001/transitory/self-attentive-parser/results'\n",
    "\n",
    "def read_parseval_files(model_id, split):\n",
    "    log_file = os.path.join(data_dir, split + '_bert_freeze_' + str(model_id) + \\\n",
    "            '_results.txt')\n",
    "    decoded_file = os.path.join(data_dir, split + '_bert_freeze_' + str(model_id) + \\\n",
    "            '_predicted.txt')\n",
    "    score_file = os.path.join(data_dir, split + '_bert_freeze_' + str(model_id) + \\\n",
    "            '_predicted.txt.scores')\n",
    "    sent_id_file = os.path.join(gold_dir, 'swbd_' + split + '_sent_ids.txt')\n",
    "    gold_file = os.path.join(gold_dir, 'swbd_' + split + '_gold.txt')\n",
    "    \n",
    "    sent_ids = open(sent_id_file).readlines()\n",
    "    sent_ids = [x.strip() for x in sent_ids]\n",
    "    decoded = open(decoded_file).readlines()\n",
    "    decoded = [x.strip() for x in decoded]\n",
    "    scores = open(score_file).readlines()\n",
    "    scores = [x.strip().split() for x in scores]\n",
    "    label = open(gold_file).readlines()\n",
    "    label = [x.strip() for x in label]\n",
    "    assert len(sent_ids) == len(label) == len(decoded) == len(scores)\n",
    "    ll = open(log_file).read()\n",
    "    results = []\n",
    "    _, res, _ = ll.split(\"============================================================================\\n\")\n",
    "    res = res.split('\\n')\n",
    "    res = [x.strip().split() for x in res]\n",
    "    res = [x for x in res if x]\n",
    "    assert len(res) == len(sent_ids)\n",
    "    for line in res:\n",
    "        sent_num, sent_len, stat, recall, precision, match, gold, test, \\\n",
    "                cross, w, tag, tag_accuracy = line\n",
    "        sent_num = int(sent_num)\n",
    "        p, r, f = calc_prf(float(match), float(gold), float(test))\n",
    "        wav_id = sent_ids[sent_num-1]\n",
    "        pscore, oscore, _ = scores[sent_num-1]\n",
    "        pscore = float(pscore)\n",
    "        oscore = float(oscore)\n",
    "        results.append({'sent_id': wav_id, \\\n",
    "                'match_' + str(model_id): int(match), \\\n",
    "                'gold_' + str(model_id): int(gold), \\\n",
    "                'test_' + str(model_id): int(test), \\\n",
    "                'f1_' + str(model_id): f, \\\n",
    "                'pscore_' + str(model_id): pscore, \\\n",
    "                'ocore_' + str(model_id): oscore, \\\n",
    "                'label_mrg': label[sent_num-1], \\\n",
    "                'decoded_mrg_' + str(model_id): decoded[sent_num-1]})\n",
    "    results = pd.DataFrame(results)\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_res(dev_df, clf, feat_list):\n",
    "    current_df = dev_df.copy()\n",
    "    Xdev = dev_df[feat_list].values\n",
    "    pred_dev = clf.predict(Xdev) \n",
    "    pred_scores = clf.predict_proba(Xdev)\n",
    "    rank_scores = pred_scores[:,1]\n",
    "    current_df.loc[:,'pred_scores'] = rank_scores\n",
    "    # dev based on pred scores\n",
    "    col = 'pred_scores'\n",
    "    idxf1 = current_df.groupby('orig_id')[col].idxmax()\n",
    "    m = current_df.loc[idxf1]['overall_match'].sum()\n",
    "    t = current_df.loc[idxf1]['overall_test'].sum()\n",
    "    g = current_df.loc[idxf1]['overall_gold'].sum()\n",
    "    ff_pred = 2 * m / (t + g)\n",
    "    print(\"Pred F1\", ff_pred)\n",
    "    return current_df.loc[idxf1], ff_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_by_pair(dev_df, clf, feat_list):  \n",
    "    save_cols = ['sent_num', \n",
    "                 'overall_match', 'overall_gold', 'overall_test', 'overall_f1',\n",
    "                'pred_parse', 'pscores_raw', 'sent_id', 'asr_hyp', 'orig_id',\n",
    "                'start_times_asr', 'end_times_asr', 'true_speaker', 'asr_sent',\n",
    "                'gold_parse', 'orig_sent', 'asr_score', 'asr_len', 'parse_score', \n",
    "                'asr_norm', 'wer']\n",
    "    list_row = []\n",
    "    for orig_id, sent_df in dev_df.groupby('orig_id'):\n",
    "        first_row = sent_df.iloc[0]\n",
    "        for i in range(1, len(sent_df)):\n",
    "            x = []\n",
    "            next_row = sent_df.iloc[i]\n",
    "            for feat in feat_list:\n",
    "                featval = next_row[feat] - first_row[feat]\n",
    "                x.append(featval)\n",
    "            x = np.array(x).reshape(1, len(feat_list))\n",
    "            pred = clf.predict(x)\n",
    "            #print(i, pred, x)\n",
    "            if pred > 0:\n",
    "                first_row = next_row.copy()\n",
    "                del next_row    \n",
    "        save_row = {}\n",
    "        for col in save_cols:\n",
    "            save_row.update({col: first_row[col]})\n",
    "        list_row.append(save_row)\n",
    "    return pd.DataFrame(list_row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_oracles(df, dep=True):\n",
    "    if dep:\n",
    "        prefix = 'overall'\n",
    "    else:\n",
    "        prefix = 'bracket'\n",
    "    col = 'wer'\n",
    "    idxf1 = df.groupby('orig_id')[col].idxmin()\n",
    "    m = df.loc[idxf1][prefix+'_match'].sum()\n",
    "    t = df.loc[idxf1][prefix+'_test'].sum()\n",
    "    g = df.loc[idxf1][prefix+'_gold'].sum()\n",
    "    ff_wer = 2 * m / (t + g)\n",
    "    ref = df.loc[idxf1].orig_sent.values\n",
    "    asr = df.loc[idxf1].asr_sent.values\n",
    "    ref = [x.split() for x in ref]\n",
    "    asr = [x.split() for x in asr]\n",
    "    flat_ref = [item for sublist in ref for item in sublist]\n",
    "    flat_asr = [item for sublist in asr for item in sublist]\n",
    "    wer = jiwer.wer(flat_ref, flat_asr)\n",
    "    print(\"Oracle F1 and WER by sent_wer:\\t\", ff_wer, \"\\t\", wer)\n",
    "\n",
    "    col = 'asr_norm'\n",
    "    idxf1 = df.groupby('orig_id')[col].idxmax()\n",
    "    m = df.loc[idxf1][prefix+'_match'].sum()\n",
    "    t = df.loc[idxf1][prefix+'_test'].sum()\n",
    "    g = df.loc[idxf1][prefix+'_gold'].sum()\n",
    "    ff_asr = 2 * m / (t + g)\n",
    "    ref = df.loc[idxf1].orig_sent.values\n",
    "    asr = df.loc[idxf1].asr_sent.values\n",
    "    ref = [x.split() for x in ref]\n",
    "    asr = [x.split() for x in asr]\n",
    "    flat_ref = [item for sublist in ref for item in sublist]\n",
    "    flat_asr = [item for sublist in asr for item in sublist]\n",
    "    wer = jiwer.wer(flat_ref, flat_asr)\n",
    "    print(\"F1 and WER by asr_score:\\t\", ff_asr, \"\\t\", wer)\n",
    "\n",
    "    col = prefix + '_f1'\n",
    "    idxf1 = df.groupby('orig_id')[col].idxmax()\n",
    "    m = df.loc[idxf1][prefix+'_match'].sum()\n",
    "    t = df.loc[idxf1][prefix+'_test'].sum()\n",
    "    g = df.loc[idxf1][prefix+'_gold'].sum()\n",
    "    ff_oracle = 2 * m / (t + g)\n",
    "    ref = df.loc[idxf1].orig_sent.values\n",
    "    asr = df.loc[idxf1].asr_sent.values\n",
    "    ref = [x.split() for x in ref]\n",
    "    asr = [x.split() for x in asr]\n",
    "    flat_ref = [item for sublist in ref for item in sublist]\n",
    "    flat_asr = [item for sublist in asr for item in sublist]\n",
    "    wer = jiwer.wer(flat_ref, flat_asr)\n",
    "    print(\"Oracle F1 and WER by sentence f1:\\t\", ff_oracle, \"\\t\", wer)\n",
    "\n",
    "    col = 'parse_score'\n",
    "    idxf1 = df.groupby('orig_id')[col].idxmax()\n",
    "    m = df.loc[idxf1][prefix+'_match'].sum()\n",
    "    t = df.loc[idxf1][prefix+'_test'].sum()\n",
    "    g = df.loc[idxf1][prefix+'_gold'].sum()\n",
    "    ff_parse = 2 * m / (t + g)\n",
    "    ref = df.loc[idxf1].orig_sent.values\n",
    "    asr = df.loc[idxf1].asr_sent.values\n",
    "    ref = [x.split() for x in ref]\n",
    "    asr = [x.split() for x in asr]\n",
    "    flat_ref = [item for sublist in ref for item in sublist]\n",
    "    flat_asr = [item for sublist in asr for item in sublist]\n",
    "    wer = jiwer.wer(flat_ref, flat_asr)\n",
    "    print(\"F1 and WER by parse_score:\\t\", ff_parse, \"\\t\", wer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_node_add(nodes):\n",
    "    summaries = [(x.span[0], x.span[1], x.word_yield(as_list=True)) for x in nodes]\n",
    "    if len(summaries) <= 1:\n",
    "        return summaries\n",
    "    summaries = sorted(summaries, key=lambda x: x[0])\n",
    "    merged = [summaries[0]]\n",
    "    for i, j, words in summaries[1:]: \n",
    "        if i < merged[-1][1]:\n",
    "            continue\n",
    "        else:\n",
    "            merged.append((i, j, words))\n",
    "    return merged\n",
    "\n",
    "PREFIXES = ['overall_', 'open_']\n",
    "def include_edits(row):\n",
    "    count_edit_gold = row.gold_parse.count('EDITED')\n",
    "    count_edit_pred = row.pred_parse.count('EDITED')\n",
    "    if count_edit_gold > 0 or count_edit_pred > 0:\n",
    "        goldtree = tree_from_text(row.gold_parse)\n",
    "        edit_nodes_gold = [x for x in goldtree.get_nodes() if x.label == 'EDITED']\n",
    "        predtree = tree_from_text(row.pred_parse)\n",
    "        edit_nodes_pred = [x for x in predtree.get_nodes() if x.label == 'EDITED']\n",
    "        gold_spans = get_node_add(edit_nodes_gold)\n",
    "        test_spans = get_node_add(edit_nodes_pred)\n",
    "        \n",
    "        gold_add = sum([x[1]-x[0] for x in gold_spans])\n",
    "        test_add = sum([x[1]-x[0] for x in test_spans])\n",
    "        gold_words = [x[-1] for x in gold_spans]\n",
    "        test_words = [x[-1] for x in test_spans]\n",
    "        gold_words = [item for sublist in gold_words for item in sublist]\n",
    "        test_words = [item for sublist in test_words for item in sublist]\n",
    "        match_add = len(set(gold_words).intersection(test_words))\n",
    "\n",
    "        bracket_gold = len(gold_spans)\n",
    "        bracket_test = len(test_spans)\n",
    "        bracket_match = min(bracket_gold, bracket_test)\n",
    "        row['bracket_gold'] += bracket_gold\n",
    "        row['bracket_test'] += bracket_test\n",
    "        row['bracket_match'] += bracket_match\n",
    "        \n",
    "        for prefix in PREFIXES:\n",
    "            row[prefix+'gold'] += gold_add\n",
    "            row[prefix+'test'] += test_add\n",
    "            row[prefix+'match'] += match_add\n",
    "        \n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = 'dev'\n",
    "asr_dir = 'asr_output/nbest/for_parsing'\n",
    "dep_type = 'unlabeled'\n",
    "model = '1704'\n",
    "add_edit = False\n",
    "\n",
    "# reading model without bracketing:\n",
    "# df = read_result_file(asr_dir, split, model, dep_type)\n",
    "\n",
    "filename = os.path.join(asr_dir, \"{}_{}_bradep_{}.tsv\".format(split, dep_type, model))\n",
    "df = pd.read_csv(filename, sep=\"\\t\")\n",
    "df = add_parses(asr_dir, split, model, df)\n",
    "\n",
    "merge_df = get_merge_df(asr_dir, split, model, dep_type, df)\n",
    "merge_df['gold_len'] = merge_df.orig_sent.apply(lambda x: len(x.split()))\n",
    "\n",
    "if add_edit:\n",
    "    merge_df = merge_df.apply(lambda row: include_edits(row), axis=1)\n",
    "    assert (merge_df.gold_len != merge_df.overall_gold).sum() == 0\n",
    "merge_df = add_f1_scores(merge_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute_oracles(merge_df)\n",
    "#merge_df.iloc[120]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oracle F1 and WER by sent_wer:\t 0.8068338829889161 \t 0.11154326989859703\n",
      "F1 and WER by asr_score:\t 0.67097007850531 \t 0.24749469172305677\n",
      "Oracle F1 and WER by sentence f1:\t 0.8320037256013606 \t 0.13541563312364813\n",
      "F1 and WER by parse_score:\t 0.6862571941898352 \t 0.22733316135177506\n"
     ]
    }
   ],
   "source": [
    "compute_oracles(merge_df, dep=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oracle F1 and WER by sent_wer:\t 0.8315499194065212 \t 0.11154326989859703\n",
      "F1 and WER by asr_score:\t 0.6697302287414094 \t 0.24749469172305677\n",
      "Oracle F1 and WER by sentence f1:\t 0.8661473773954155 \t 0.15172742245946857\n",
      "F1 and WER by parse_score:\t 0.735074411905905 \t 0.22733316135177506\n"
     ]
    }
   ],
   "source": [
    "compute_oracles(merge_df, dep=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_df = get_merge_df(asr_dir, split, '1704', dep_type)\n",
    "print(\"text model\")\n",
    "compute_oracles(text_df)\n",
    "\n",
    "speech_df = merge_df.copy()\n",
    "print(\"speech model\")\n",
    "compute_oracles(speech_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5718\n",
      "5718\n",
      "Pred F1 (dependency) 0.9267463363226025\n",
      "Pred F1 (bracket) 0.9328257577329212\n"
     ]
    }
   ],
   "source": [
    "res_dir = \"/homes/ttmt001/transitory/self-attentive-parser/results\"\n",
    "columns = ['sent_num', \n",
    "'bracket_match', 'bracket_gold', 'bracket_test', 'bracket_cross', \n",
    "'overall_match', 'overall_gold', 'overall_test', \n",
    "'open_match', 'open_gold', 'open_test']\n",
    "\n",
    "def read_oracle(split, model, dep_type):\n",
    "    filename = \"asr_output/nbest/for_parsing/{}_{}_bradep_oracle_{}.log\".format(split, dep_type, model)\n",
    "    pred_file = res_dir + \"/bert/{}_bert_freeze_{}_predicted.txt\".format(split, model)\n",
    "    score_file = res_dir + \"/bert/{}_bert_freeze_{}_predicted.txt.scores\".format(split, model)\n",
    "    sent_id_file = res_dir + \"/swbd_{}_sent_ids.txt\".format(split)\n",
    "    gold_file = res_dir + \"/swbd_{}_gold.txt\".format(split)\n",
    "    ll = open(filename).readlines()\n",
    "    lines = ll[4:-22]\n",
    "    lines = [x.split() for x in lines]\n",
    "    df = pd.DataFrame(lines, columns=columns, dtype=float)\n",
    "    print(len(df))\n",
    "    \n",
    "    parses = open(pred_file).readlines()\n",
    "    parses = [x.strip() for x in parses]\n",
    "    print(len(parses))\n",
    "    df['pred_parse'] = parses\n",
    "    \n",
    "    sent_ids = open(sent_id_file).readlines()\n",
    "    sent_ids = [x.strip() for x in sent_ids]\n",
    "    df['orig_id'] = sent_ids\n",
    "    \n",
    "    scores = open(score_file).readlines()\n",
    "    scores = [x.strip().split()[0] for x in scores]\n",
    "    df['pscores_raw'] = scores\n",
    "    \n",
    "    label = open(gold_file).readlines()\n",
    "    label = [x.strip() for x in label]\n",
    "    df['gold_parse'] = label\n",
    "    df['gold_sent'] = df.gold_parse.apply(lambda x: tree_from_text(x).word_yield(as_list=True))\n",
    "    df['gold_len'] = df.gold_sent.apply(lambda x: len(x))\n",
    "    assert len(sent_ids) == len(label) == len(parses) == len(scores)\n",
    "    return df\n",
    "\n",
    "split = 'dev'\n",
    "dep_type = 'unlabeled'\n",
    "model = '1704'\n",
    "dev_oracle = read_oracle(split, model, dep_type)\n",
    "dev = dev_oracle.apply(lambda row: include_edits(row), axis=1)\n",
    "assert (dev.gold_len != dev.overall_gold).sum() == 0\n",
    "dev = add_f1_scores(dev)\n",
    "m = dev['overall_match'].sum()\n",
    "t = dev['overall_test'].sum()\n",
    "g = dev['overall_gold'].sum()\n",
    "ff_pred = 2 * m / (t + g)\n",
    "print(\"Pred F1 (dependency)\", ff_pred)\n",
    "\n",
    "m = dev['bracket_match'].sum()\n",
    "t = dev['bracket_test'].sum()\n",
    "g = dev['bracket_gold'].sum()\n",
    "ff_pred = 2 * m / (t + g)\n",
    "print(\"Pred F1 (bracket)\", ff_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S (EDITED (NP (PRP i))) (NP (PRP i)) (VP (VBP 've) (VP (VBN done) (NP (DT the) (JJ same)) (PRN (S (NP (PRP you)) (VP (VBP know)))) (INTJ (IN like)) (NP (NP (NP (DT the) (NN trim)) (PP (IN around) (NP (DT the) (NN house)))) (PRN (S (NP (PRP you)) (VP (VBP know)))) (NP (NP (DT the) (NNS baseboards)) (CC and) (NP (NP (NNS things)) (PP (IN like) (NP (DT that)))))))))\n",
      "(S (EDITED (NP (PRP i))) (NP (PRP i)) (VP (VBP 've) (VP (VBN done) (NP (NP (DT the) (JJ same)) (PRN (S (NP (PRP you)) (VP (VBP know)))) (PP (IN like) (NP (NP (NP (DT the) (NN trim)) (PP (IN around) (NP (DT the) (NN house)))) (PRN (S (NP (PRP you)) (VP (VBP know)))) (NP (DT the) (NNS baseboards)) (CC and) (NP (NP (NNS things)) (PP (IN like) (NP (DT that))))))))))\n"
     ]
    }
   ],
   "source": [
    "print(dev.iloc[5713].pred_parse)\n",
    "print(dev.iloc[5713].gold_parse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bracket_match</th>\n",
       "      <th>bracket_gold</th>\n",
       "      <th>bracket_test</th>\n",
       "      <th>overall_match</th>\n",
       "      <th>overall_gold</th>\n",
       "      <th>overall_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5713</th>\n",
       "      <td>24.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5714</th>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5715</th>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5716</th>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5717</th>\n",
       "      <td>25.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5718 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      bracket_match  bracket_gold  bracket_test  overall_match  overall_gold  \\\n",
       "0               0.0           0.0           0.0            2.0           2.0   \n",
       "1              13.0          13.0          13.0           12.0          12.0   \n",
       "2              13.0          13.0          13.0           15.0          15.0   \n",
       "3              16.0          16.0          16.0           14.0          18.0   \n",
       "4              18.0          18.0          18.0           19.0          19.0   \n",
       "...             ...           ...           ...            ...           ...   \n",
       "5713           24.0          26.0          26.0           19.0          22.0   \n",
       "5714           11.0          11.0          11.0           12.0          12.0   \n",
       "5715           15.0          15.0          15.0           13.0          13.0   \n",
       "5716            9.0           9.0           9.0            8.0           8.0   \n",
       "5717           25.0          25.0          25.0           24.0          24.0   \n",
       "\n",
       "      overall_test  \n",
       "0              2.0  \n",
       "1             12.0  \n",
       "2             15.0  \n",
       "3             18.0  \n",
       "4             19.0  \n",
       "...            ...  \n",
       "5713          22.0  \n",
       "5714          12.0  \n",
       "5715          13.0  \n",
       "5716           8.0  \n",
       "5717          24.0  \n",
       "\n",
       "[5718 rows x 6 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev[['bracket_match', 'bracket_gold', 'bracket_test', 'overall_match', 'overall_gold', 'overall_test']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent_num</th>\n",
       "      <th>bracket_match</th>\n",
       "      <th>bracket_gold</th>\n",
       "      <th>bracket_test</th>\n",
       "      <th>bracket_cross</th>\n",
       "      <th>overall_match</th>\n",
       "      <th>overall_gold</th>\n",
       "      <th>overall_test</th>\n",
       "      <th>open_match</th>\n",
       "      <th>open_gold</th>\n",
       "      <th>open_test</th>\n",
       "      <th>pred_parse</th>\n",
       "      <th>orig_id</th>\n",
       "      <th>pscores_raw</th>\n",
       "      <th>gold_parse</th>\n",
       "      <th>gold_sent</th>\n",
       "      <th>gold_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>(NP (PRP$ your) (NN turn))</td>\n",
       "      <td>sw4519_A_0001</td>\n",
       "      <td>1.4354355335235596</td>\n",
       "      <td>(NP (PRP$ your) (NN turn))</td>\n",
       "      <td>[your, turn]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(INTJ (UH yeah))</td>\n",
       "      <td>sw4519_A_0024</td>\n",
       "      <td>1.994942307472229</td>\n",
       "      <td>(INTJ (UH yeah))</td>\n",
       "      <td>[yeah]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(S (CC but))</td>\n",
       "      <td>sw4519_A_0029</td>\n",
       "      <td>0.44012364745140076</td>\n",
       "      <td>(S (CC but))</td>\n",
       "      <td>[but]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(INTJ (UH yeah))</td>\n",
       "      <td>sw4519_A_0032</td>\n",
       "      <td>1.994942307472229</td>\n",
       "      <td>(INTJ (UH yeah))</td>\n",
       "      <td>[yeah]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(INTJ (UH yeah))</td>\n",
       "      <td>sw4519_A_0034</td>\n",
       "      <td>1.994942307472229</td>\n",
       "      <td>(INTJ (UH yeah))</td>\n",
       "      <td>[yeah]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5695</th>\n",
       "      <td>5696.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(INTJ (UH uh-huh))</td>\n",
       "      <td>sw4936_B_0096</td>\n",
       "      <td>1.978058934211731</td>\n",
       "      <td>(INTJ (UH uh-huh))</td>\n",
       "      <td>[uh-huh]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5696</th>\n",
       "      <td>5697.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(INTJ (UH uh-huh))</td>\n",
       "      <td>sw4936_B_0099</td>\n",
       "      <td>1.978058934211731</td>\n",
       "      <td>(INTJ (UH uh-huh))</td>\n",
       "      <td>[uh-huh]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5697</th>\n",
       "      <td>5698.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(INTJ (UH right))</td>\n",
       "      <td>sw4936_B_0100</td>\n",
       "      <td>1.9782383441925049</td>\n",
       "      <td>(INTJ (UH right))</td>\n",
       "      <td>[right]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5698</th>\n",
       "      <td>5699.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(INTJ (UH yeah))</td>\n",
       "      <td>sw4936_B_0104</td>\n",
       "      <td>1.994942307472229</td>\n",
       "      <td>(INTJ (UH yeah))</td>\n",
       "      <td>[yeah]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5705</th>\n",
       "      <td>5706.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(INTJ (UH yeah))</td>\n",
       "      <td>sw4936_B_0119</td>\n",
       "      <td>1.994942307472229</td>\n",
       "      <td>(INTJ (UH yeah))</td>\n",
       "      <td>[yeah]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1504 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      sent_num  bracket_match  bracket_gold  bracket_test  bracket_cross  \\\n",
       "0          1.0            0.0           0.0           0.0            0.0   \n",
       "11        12.0            0.0           0.0           0.0            0.0   \n",
       "13        14.0            0.0           0.0           0.0            0.0   \n",
       "14        15.0            0.0           0.0           0.0            0.0   \n",
       "15        16.0            0.0           0.0           0.0            0.0   \n",
       "...        ...            ...           ...           ...            ...   \n",
       "5695    5696.0            0.0           0.0           0.0            0.0   \n",
       "5696    5697.0            0.0           0.0           0.0            0.0   \n",
       "5697    5698.0            0.0           0.0           0.0            0.0   \n",
       "5698    5699.0            0.0           0.0           0.0            0.0   \n",
       "5705    5706.0            0.0           0.0           0.0            0.0   \n",
       "\n",
       "      overall_match  overall_gold  overall_test  open_match  open_gold  \\\n",
       "0               2.0           2.0           2.0         2.0        2.0   \n",
       "11              1.0           1.0           1.0         1.0        1.0   \n",
       "13              1.0           1.0           1.0         1.0        1.0   \n",
       "14              1.0           1.0           1.0         1.0        1.0   \n",
       "15              1.0           1.0           1.0         1.0        1.0   \n",
       "...             ...           ...           ...         ...        ...   \n",
       "5695            1.0           1.0           1.0         1.0        1.0   \n",
       "5696            1.0           1.0           1.0         1.0        1.0   \n",
       "5697            1.0           1.0           1.0         1.0        1.0   \n",
       "5698            1.0           1.0           1.0         1.0        1.0   \n",
       "5705            1.0           1.0           1.0         1.0        1.0   \n",
       "\n",
       "      open_test                  pred_parse        orig_id  \\\n",
       "0           2.0  (NP (PRP$ your) (NN turn))  sw4519_A_0001   \n",
       "11          1.0            (INTJ (UH yeah))  sw4519_A_0024   \n",
       "13          1.0                (S (CC but))  sw4519_A_0029   \n",
       "14          1.0            (INTJ (UH yeah))  sw4519_A_0032   \n",
       "15          1.0            (INTJ (UH yeah))  sw4519_A_0034   \n",
       "...         ...                         ...            ...   \n",
       "5695        1.0          (INTJ (UH uh-huh))  sw4936_B_0096   \n",
       "5696        1.0          (INTJ (UH uh-huh))  sw4936_B_0099   \n",
       "5697        1.0           (INTJ (UH right))  sw4936_B_0100   \n",
       "5698        1.0            (INTJ (UH yeah))  sw4936_B_0104   \n",
       "5705        1.0            (INTJ (UH yeah))  sw4936_B_0119   \n",
       "\n",
       "              pscores_raw                  gold_parse     gold_sent  gold_len  \n",
       "0      1.4354355335235596  (NP (PRP$ your) (NN turn))  [your, turn]         2  \n",
       "11      1.994942307472229            (INTJ (UH yeah))        [yeah]         1  \n",
       "13    0.44012364745140076                (S (CC but))         [but]         1  \n",
       "14      1.994942307472229            (INTJ (UH yeah))        [yeah]         1  \n",
       "15      1.994942307472229            (INTJ (UH yeah))        [yeah]         1  \n",
       "...                   ...                         ...           ...       ...  \n",
       "5695    1.978058934211731          (INTJ (UH uh-huh))      [uh-huh]         1  \n",
       "5696    1.978058934211731          (INTJ (UH uh-huh))      [uh-huh]         1  \n",
       "5697   1.9782383441925049           (INTJ (UH right))       [right]         1  \n",
       "5698    1.994942307472229            (INTJ (UH yeah))        [yeah]         1  \n",
       "5705    1.994942307472229            (INTJ (UH yeah))        [yeah]         1  \n",
       "\n",
       "[1504 rows x 17 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dev_oracle[['bracket_match', 'bracket_gold', 'bracket_test', 'overall_match', 'overall_gold', 'overall_test']]\n",
    "dev_oracle[dev_oracle.bracket_gold == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('rank_exp_sents_split.json', 'r') as f:\n",
    "    data_split = json.load(f)\n",
    "    \n",
    "train_sents = set(data_split['train'])\n",
    "dev_sents = set(data_split['dev'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_df = merge_df[merge_df.orig_id.isin(dev_sents)]\n",
    "train_df = merge_df[merge_df.orig_id.isin(train_sents)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33271"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_df.sent_num)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "compute_oracles(dev_df)\n",
    "\n",
    "n = 2\n",
    "all_feats = ['parse_score', 'asr_score', 'asr_len', \n",
    "             'edit_count', 'depth_proxy', 'intj_count',\n",
    "             'np_count', 'vp_count', 'pp_count']\n",
    "\n",
    "\n",
    "Xall, Ytrain, WER_diffs, pair_idx = make_pairs(train_df, feat_list=all_feats, n=n)\n",
    "\n",
    "#np.histogram(WER_diffs)\n",
    "\n",
    "feat_list = all_feats[:]\n",
    "Xtrain = Xall[:, :]\n",
    "\n",
    "#clf = LogisticRegression(random_state=1, max_iter=200, C=0.001, penalty='elasticnet', solver='saga', l1_ratio=0.5)\n",
    "clf = LogisticRegression(random_state=1, C=0.0001)\n",
    "#clf = SVC(probability=True, kernel='poly', degree=3, gamma='scale', C=1, random_state=1, max_iter=300)\n",
    "#clf = SVC(probability=True, C=0.001, gamma='auto', random_state=1, max_iter=300)\n",
    "\n",
    "clf.fit(Xtrain, Ytrain)\n",
    "\n",
    "res_df, _ = get_res(dev_df, clf, feat_list)\n",
    "pred_df = pred_by_pair(dev_df, clf, feat_list)\n",
    "m = pred_df['overall_match'].sum()\n",
    "t = pred_df['overall_test'].sum()\n",
    "g = pred_df['overall_gold'].sum()\n",
    "ff_pred = 2 * m / (t + g)\n",
    "print(\"Pred F1 (pair)\", ff_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = get_merge_df(asr_dir, 'test', model, dep_type)\n",
    "compute_oracles(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_res = get_res(test_df, clf, feat_list)\n",
    "pair_df = pred_by_pair(test_df, clf, feat_list)\n",
    "m = pair_df['overall_match'].sum()\n",
    "t = pair_df['overall_test'].sum()\n",
    "g = pair_df['overall_gold'].sum()\n",
    "ff_pred = 2 * m / (t + g)\n",
    "print(\"Pred F1 (pair)\", ff_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare/Check original sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_bracket_df = read_parseval_files(1704, 'dev')\n",
    "speech_bracket_df = read_parseval_files(3704, 'dev')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_df.iloc[400][['overall_match', 'overall_gold', 'overall_test', 'sent_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_bracket_df[text_bracket_df.sent_id == 'sw4519_A_0083']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop = ['sent_num', 'asr_hyp', 'orig_id',\n",
    "       'start_times_asr', 'end_times_asr', \n",
    "       'true_speaker', 'asr_sent',\n",
    "       'lm_cost', 'ac_cost', 'gold_parse', \n",
    "       'orig_sent', 'asr_score', 'asr_len',\n",
    "       'asr_norm', 'wer']\n",
    "\n",
    "to_rename = ['overall_match', 'overall_gold', 'overall_test',\n",
    "       'open_match', 'open_gold', 'open_test', 'overall_f1', 'open_f1',\n",
    "       'pred_parse', 'pscores_raw', 'parse_score', 'edit_count', 'intj_count',\n",
    "       'np_count', 'vp_count', 'pp_count', 'depth_proxy', 'depth']\n",
    "\n",
    "text_names = [x+'_1704' for x in to_rename]\n",
    "text_cols = dict(zip(to_rename, text_names))\n",
    "speech_names = [x+'_3704' for x in to_rename]\n",
    "speech_cols = dict(zip(to_rename, speech_names))\n",
    "\n",
    "temp = text_df.drop(columns=to_drop)\n",
    "temp = temp.rename(columns=text_cols)\n",
    "sp = speech_df.rename(columns=speech_cols)\n",
    "df = pd.merge(temp, sp, on='sent_id')\n",
    "df['delta'] = df.overall_f1_3704 - df.overall_f1_1704"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_cols = ['sent_id', 'overall_f1_1704', 'overall_f1_3704', 'wer', 'delta']\n",
    "\n",
    "temp_df = df[df.gold_parse.str.contains(\"EDITED\")]\n",
    "temp_df.sort_values('delta')[display_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[32746]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 32746\n",
    "print(text_df.iloc[idx].pred_parse)\n",
    "print(speech_df.iloc[idx].pred_parse)\n",
    "print(text_df.iloc[idx].gold_parse)\n",
    "\n",
    "print(speech_df.iloc[idx].asr_sent)\n",
    "print(text_df.iloc[idx].asr_sent)\n",
    "print(text_df.iloc[idx].orig_sent)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_df = get_merge_df(asr_dir, 'dev', '1704', dep_type)\n",
    "\n",
    "X, Y, WER_diffs = [], [], []\n",
    "for k in pair_idx.keys():\n",
    "    sent_df = text_df[text_df.orig_id==k]\n",
    "    for i0, i1 in pair_idx[k]:\n",
    "        wer_delta = sent_df.loc[i0].wer - sent_df.loc[i1].wer\n",
    "        diff = sent_df.loc[i0].overall_f1 - sent_df.loc[i1].overall_f1\n",
    "        x = []\n",
    "        for feat in feat_list:\n",
    "            featval = sent_df.loc[i0][feat] -  sent_df.loc[i1][feat]\n",
    "            x.append(featval)\n",
    "        if diff > 0:\n",
    "            y = 1\n",
    "        else:\n",
    "            y = 0\n",
    "        WER_diffs.append(wer_delta)\n",
    "        X.append(x)\n",
    "        Y.append(y)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(Ytrain)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx, yy, wers, pidx = make_pairs(merge_df.head(100), feat_list=all_feats, n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dev_df\n",
    "\n",
    "col = 'wer'\n",
    "idxf1 = df.groupby('orig_id')[col].idxmin()\n",
    "m = df.loc[idxf1]['overall_match'].sum()\n",
    "t = df.loc[idxf1]['overall_test'].sum()\n",
    "g = df.loc[idxf1]['overall_gold'].sum()\n",
    "ff_asr = 2 * m / (t + g)\n",
    "print(\"ASR F1\", ff_asr)\n",
    "\n",
    "ref = df.loc[idxf1].orig_sent.values\n",
    "asr = df.loc[idxf1].asr_sent.values\n",
    "\n",
    "ref = [x.split() for x in ref]\n",
    "asr = [x.split() for x in asr]\n",
    "\n",
    "flat_ref = [item for sublist in ref for item in sublist]\n",
    "flat_asr = [item for sublist in asr for item in sublist]\n",
    "wer = jiwer.wer(flat_ref, flat_asr)\n",
    "print(\"WER\", wer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pidx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goldtree = tree_from_text(merge_df.iloc[idx].gold_parse)\n",
    "edit_nodes_gold = [x for x in goldtree.get_nodes() if x.label == 'EDITED']\n",
    "predtree = tree_from_text(merge_df.iloc[idx].pred_parse)\n",
    "edit_nodes_pred = [x for x in predtree.get_nodes() if x.label == 'EDITED']\n",
    "\n",
    "\n",
    "gold_spans = get_node_add(edit_nodes_gold)\n",
    "test_spans = get_node_add(edit_nodes_pred)\n",
    "\n",
    "gold_add = sum([x[1]-x[0] for x in gold_spans])\n",
    "test_add = sum([x[1]-x[0] for x in test_spans])\n",
    "\n",
    "gold_words = [x[-1] for x in gold_spans]\n",
    "test_words = [x[-1] for x in test_spans]\n",
    "\n",
    "gold_words = [item for sublist in gold_words for item in sublist]\n",
    "test_words = [item for sublist in test_words for item in sublist]\n",
    "match_add = len(set(gold_words).intersection(test_words))\n",
    "\n",
    "test_spans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fix dev/train set within all_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_dir = '/homes/ttmt001/transitory/self-attentive-parser/results'\n",
    "\n",
    "sent_id_file = os.path.join(gold_dir, 'swbd_dev_sent_ids.txt')\n",
    "sent_ids = open(sent_id_file).readlines()\n",
    "sent_ids = [x.strip() for x in sent_ids]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = len(sent_ids) // 4\n",
    "dev_sents = random.sample(sent_ids, num_samples)\n",
    "all_dev = set(sent_ids)\n",
    "dev_sents = set(dev_sents)\n",
    "train_sents = all_dev.difference(dev_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1429"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dev_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = {}\n",
    "splits['train'] = list(train_sents)\n",
    "splits['dev'] = list(dev_sents)\n",
    "with open('rank_exp_sents_split.json', 'w') as f:\n",
    "    json.dump(splits, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.6-transformers-cpu",
   "language": "python",
   "name": "py3.6-transformers-cpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
